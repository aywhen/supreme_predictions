{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Justice-centered data into pandas df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainX = pd.read_csv('../data/trainX_justice.csv')\n",
    "trainY = pd.read_csv('../data/trainY_justice.csv')\n",
    "testX = pd.read_csv('../data/testX_justice.csv')\n",
    "testY = pd.read_csv('../data/testY_justice.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables (from preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# column names by category\n",
    "id_variables_to_drop = [\n",
    "    u'justiceName', #Name and unique ID\n",
    "    ]\n",
    "id_variables_to_keep = [\n",
    "    u'justice',  #Name and unique ID\n",
    "    u'caseId', u'docketId', u'caseIssuesId', u'voteId',\n",
    "    u'usCite', u'sctCite', u'ledCite', u'lexisCite',\n",
    "    u'docket']\n",
    "    \n",
    "bg_variables = [\n",
    "    u'caseName', u'petitioner', u'petitionerState',\n",
    "    u'respondent', u'respondentState', u'jurisdiction',\n",
    "    u'adminAction', u'adminActionState', u'threeJudgeFdc',\n",
    "    u'caseOrigin', u'caseOriginState', u'caseSource',\n",
    "    u'caseSourceState', u'lcDisagreement', u'certReason',\n",
    "    u'lcDisposition', u'lcDispositionDirection',\n",
    "]\n",
    "\n",
    "chrono_include = [u'naturalCourt', u'chief']\n",
    "chrono_donotinclude = [u'dateDecision', u'decisionType', u'term',\n",
    "                       u'dateArgument', u'dateRearg']\n",
    "chrono_variables = chrono_include + chrono_donotinclude\n",
    "\n",
    "substantive_variables = [\n",
    "    u'issue', u'issueArea', u'decisionDirection',\n",
    "    u'decisionDirectionDissent', u'authorityDecision1',\n",
    "    u'authorityDecision2', u'lawType', u'lawSupp', u'lawMinor']\n",
    "\n",
    "outcome_variables = [\n",
    "    u'declarationUncon', u'caseDisposition',\n",
    "    u'caseDispositionUnusual', u'partyWinning', u'precedentAlteration',  \n",
    "    u'firstAgreement', u'secondAgreement']\n",
    "\n",
    "voting_variables = [u'voteUnclear', u'majOpinWriter', u'majOpinAssigner',\n",
    "                    u'splitVote', u'majVotes', u'minVotes',  u'vote', u'opinion',\n",
    "                    u'direction', u'majority']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop unimportant ID variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainX_id = trainX[id_variables_to_drop].copy()\n",
    "trainX = trainX[id_variables_to_keep + bg_variables + chrono_include + substantive_variables].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-hot encode select categorical variables\n",
    "#### + impute nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "class Categorical(object):\n",
    "    def __init__(self, df, ohe_threshold = 1000):\n",
    "        self.arr = df.copy()\n",
    "        self.arr = self.arr.fillna(-1) # Impute values\n",
    "        # Select the categorical features to OHE\n",
    "        ohe_vars = []\n",
    "        other_vars = []\n",
    "        for c in self.arr.columns:\n",
    "            u =  len(self.arr[c].unique())\n",
    "            if u < ohe_threshold:\n",
    "                print \"{0}: {1} unique\".format(c, len(self.arr[c].unique()))\n",
    "                ohe_vars.append(c)\n",
    "            else:\n",
    "                other_vars.append(c)\n",
    "        self.n_samples, self.n_features = self.arr.shape\n",
    "        self.n_cat_features = len(ohe_vars)\n",
    "        self.ohe_vars = ohe_vars\n",
    "        self.other_vars = other_vars\n",
    "        self.arr = pd.concat([self.arr[other_vars], self.arr[ohe_vars]], axis=1)\n",
    "        self.columns = other_vars + ohe_vars\n",
    "        self.other = self.arr[other_vars].copy() #ID and other features\n",
    "        self.cat = self.arr[ohe_vars].copy()\n",
    "        #Label Encode select categorical variables\n",
    "        self.LE()\n",
    "        self.cat_ohe = self.cat.copy()\n",
    "        self.n_justices = len(self.cat['justice'].unique())\n",
    "        #OHE the categorical data\n",
    "        self.OHE()\n",
    "        \n",
    "        \n",
    "    def LE(self):\n",
    "        '''Label Encode cat variables (to give reasonable feautures) '''  \n",
    "        le = []  #keep le global so we may inverse_transform if necessary\n",
    "        i = 0\n",
    "        for c in self.ohe_vars: #text_cols:\n",
    "            le.append(LabelEncoder())\n",
    "            le[i].fit(self.cat[c])\n",
    "            self.cat.loc[:,c] = le[i].transform(self.cat[c])\n",
    "            i = i + 1\n",
    "        self.le = le # label encoder (useful for reverse transforming also)\n",
    "                              \n",
    "    def OHE(self):\n",
    "        self.ohe = OneHotEncoder()\n",
    "        self.ohe.fit(self.cat_ohe)\n",
    "        self.cat_ohe =  self.ohe.transform(self.cat_ohe) \n",
    "    \n",
    "    \n",
    "    def orig_cat(self): # Not important since I cache the values, but keep for possible future functions\n",
    "        '''Returns the original array of the OHE encoded csr array\n",
    "            (requires the original one-hot encoder fit to the dataset) '''\n",
    "        return np.array([self.ohe.active_features_[col] for col in \n",
    "                            self.cat.sorted_indices().indices]).reshape(self.n_samples, self.n_cat_features) \\\n",
    "                                - self.ohe.feature_indices_[:-1]\n",
    "        \n",
    "    def getValue(self, col):\n",
    "        '''Return the original value for the label-encoded variable'''\n",
    "        if col not in self.ohe_vars:\n",
    "            return None\n",
    "        le = self.le[self.ohe_vars.index(col)]\n",
    "        return le.inverse_transform(self.cat[col])\n",
    "\n",
    "    def isolate_justice(self, ID, deep=False, ind=True):\n",
    "        '''Return sparse array for data for a single justice '''\n",
    "        \n",
    "        #Check if ID is a legal label-encodded justice id\n",
    "        if ID < 0 or ID >= self.n_justices:\n",
    "            print \"Error: Not a legal justice ID\"\n",
    "            return None\n",
    "        \n",
    "        if ind:\n",
    "            return self.cat.loc[self.cat['justice'] == ID].index\n",
    "        elif deep:\n",
    "            return self.cat.loc[self.cat['justice'] == ID].copy()\n",
    "        else:\n",
    "            return self.cat.loc[self.cat['justice'] == ID]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "justice: 36 unique\n",
      "petitioner: 260 unique\n",
      "petitionerState: 57 unique\n",
      "respondent: 240 unique\n",
      "respondentState: 56 unique\n",
      "jurisdiction: 11 unique\n",
      "adminAction: 112 unique\n",
      "adminActionState: 53 unique\n",
      "threeJudgeFdc: 3 unique\n",
      "caseOrigin: 132 unique\n",
      "caseOriginState: 53 unique\n",
      "caseSource: 109 unique\n",
      "caseSourceState: 53 unique\n",
      "lcDisagreement: 3 unique\n",
      "certReason: 14 unique\n",
      "lcDisposition: 13 unique\n",
      "lcDispositionDirection: 4 unique\n",
      "naturalCourt: 31 unique\n",
      "chief: 5 unique\n",
      "issue: 266 unique\n",
      "issueArea: 15 unique\n",
      "decisionDirection: 4 unique\n",
      "decisionDirectionDissent: 3 unique\n",
      "authorityDecision1: 8 unique\n",
      "authorityDecision2: 8 unique\n",
      "lawType: 9 unique\n",
      "lawSupp: 176 unique\n",
      "lawMinor: 828 unique\n"
     ]
    }
   ],
   "source": [
    "trainX_Cat = Categorical(df = trainX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([   1,   10,   19,   28,   42,   46,   55,   64,   73,   82,\n",
       "            ...\n",
       "            7873, 7882, 7891, 7900, 7909, 7918, 7927, 7936, 7945, 7954],\n",
       "           dtype='int64', length=884)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainX_Cat.isolate_justice(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Impute nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainX = trainX.fillna(-1); # fill with -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Note that this really only avoids the IDs at this point... may have to be more discrete\n",
    "ohe_threshold = 1000\n",
    "ohe_variables = []\n",
    "other_vars = []\n",
    "for c in trainX.columns:\n",
    "    u =  len(trainX[c].unique())\n",
    "    if u < ohe_threshold:\n",
    "        print \"{0}: {1} unique\".format(c, len(trainX[c].unique()))\n",
    "        ohe_variables.append(c)\n",
    "    else:\n",
    "        other_vars.append(c)\n",
    "n_cat_features = len(ohe_variables)\n",
    "trainX = pd.concat([trainX[ohe_variables], trainX[other_vars]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LabelEncode the categorical (and text) fields to span from 0-n (without weird jumps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# text_cols =  trainX[ohe_variables].columns[trainX[ohe_variables].dtypes == object]\n",
    "# text_cols = ohe_variables\n",
    "# print text_cols\n",
    "le = []  #keep le global so we may inverse_transform if necessary\n",
    "i = 0\n",
    "for c in ohe_variables: #text_cols:\n",
    "    le.append(LabelEncoder())\n",
    "    le[i].fit(trainX[c])\n",
    "    trainX[c] = le[i].transform(trainX[c])\n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "enc = OneHotEncoder()\n",
    "# SHIFT by 1 (so no categories are negative)\n",
    "# trainX = shift(trainX, ohe_variables)\n",
    "enc.fit(trainX[ohe_variables])\n",
    "print enc.n_values_\n",
    "print enc.feature_indices_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainX_cat =  enc.transform(trainX[ohe_variables])\n",
    "# trainX.loc[:, ohe_variables] = enc.transform(trainX[ohe_variables])\n",
    "# print trainX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print enc.active_features_\n",
    "print len(enc.active_features_)\n",
    "print enc.feature_indices_\n",
    "print enc.n_values_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print trainX_cat.indices\n",
    "trainX_cat = trainX_cat.sorted_indices()\n",
    "print trainX_cat.indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainX.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class categorical(object):\n",
    "    \n",
    "    def __init__(df, ohe_threshold = 1000):\n",
    "        df.fillna(-1) # Impute values\n",
    "        # Select the categorical features to OHE\n",
    "        ohe_vars = []\n",
    "        other_vars = []\n",
    "        for c in self.columns:\n",
    "            u =  len(df[c].unique())\n",
    "            if u < ohe_threshold:\n",
    "                print \"{0}: {1} unique\".format(c, len(df[c].unique()))\n",
    "                ohe_variables.append(c)\n",
    "            else:\n",
    "                other_vars.append(c)\n",
    "        self.n_samples, self.n_features = df.shape\n",
    "        self.n_cat_features = len(ohe_variables)\n",
    "        self.arr = pd.concat([df[other_vars], df[ohe_variables]], axis=1)\n",
    "        self.columns = other_vars + ohe_vars\n",
    "        self.other = df[other_vars] #ID and other features\n",
    "        self.cat = df[ohe_variables]\n",
    "        #Label Encode select categorical variables\n",
    "        self.LE()                 \n",
    "        #OHE the categorical data\n",
    "        self.OHE()\n",
    "           \n",
    "        return df\n",
    "    def LE(self):\n",
    "        '''Label Encode cat variables (to give reasonable feautures) '''  \n",
    "        le = []  #keep le global so we may inverse_transform if necessary\n",
    "        i = 0\n",
    "        for c in ohe_variables: #text_cols:\n",
    "            le.append(LabelEncoder())\n",
    "            le[i].fit(trainX[c])\n",
    "            trainX[c] = le[i].transform(trainX[c])\n",
    "            i = i + 1\n",
    "        self.le = le # label encoder (useful for reverse transforming also)\n",
    "                              \n",
    "    def OHE(self):\n",
    "        self.ohe = OneHotEncoder()\n",
    "        self.ohe.fit(self.cat)\n",
    "        self.cat =  self.ohe.transform(self.cat) \n",
    "    \n",
    "    \n",
    "    def orig_cat(self):\n",
    "        '''Returns the original array of the OHE encoded csr array\n",
    "            (requires the original one-hot encoder fit to the dataset) '''\n",
    "        return np.array([self.ohe.active_features_[col] for col in \n",
    "                            self.cat.sorted_indices().indices]).reshape(self.n_samples, self.n_cat_features) \\\n",
    "                                - self.ohe.feature_indices_[:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working Outline\n",
    "\n",
    "* In progress...\n",
    "\n",
    "The lack of data would indicate that an rnn may not be a particularly appropriate model for this task; however it would be fun to try in order to see how the sequence of issues or the long-term trends of a justice come into play for future decisions. \n",
    "\n",
    "### Workflow:\n",
    "\n",
    "#### Data Preparation:\n",
    "\n",
    "Impute values -> maybe categorize nan's as -1, etc. (There are no negative values here)\n",
    "\n",
    "OHE categorical variables\n",
    "\n",
    "Drop the justiceName column -> all information is in 'justice'\n",
    "\n",
    "\n",
    "#### RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill in nas with -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for c in trainX.columns:\n",
    "    print trainX[c].mode()\n",
    "    print \"Number NaN: {0}\".format(np.sum(trainX[c].isnull()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainX['authorityDecision2'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
